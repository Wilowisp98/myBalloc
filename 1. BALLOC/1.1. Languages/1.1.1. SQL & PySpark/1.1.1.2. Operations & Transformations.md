> [!NOTE]
> When converting from SQL to PySpark, the order of operations display is often reversed.


### Counting Null Values

SQL:
```sql
SELECT COUNT_IF(column1 IS NULL)
-- OR 
SELECT COUNT() FROM TABLE_1 WHERE column1 IS NULL
```

PySpark:
```python
table = spark.read.table(...)

table.selectExpr("SELECT COUNT_IF(column1 IS NULL) FROM TABLE_1")
# OR
table.where(col("column1").isNull()).count()
```

---

### Count Distinct Values

SQL:
```sql
SELECT
	COUNT(DISTINCT)
FROM 
	TABLE_1
```

PySpark:
```python
table = spark.read.table(...)

table.distinct().count()
```

---

### Deduplication

SQL:
```sql
SELECT
	key_column1,
	key_column2,
	...
	MAX(column1) 
FROM 
	TABLE_1 
GROUP BY 
	key_column1,
	key_column2
```

PySpark:
```python
new_Table = (
    table
    .where(col("user_id").isNotNull())
    .groupBy("key_column")
    .agg(max("column1").alias("column1_alias"))
)
```


---

### Counting Duplicates

SQL:
```sql
SELECT 
	user_id,
	MAX(row_count) > 1 AS duplicates 
FROM (
    SELECT 
	    user_id, 
	    COUNT(*) AS row_count 
    FROM 
	    TABLE_1
    GROUP BY 
		user_id
)
```

PySpark:
```python
# Load the table into a DataFrame
df = spark.read.table("TABLE_1")

# Group by user_id and count the rows
grouped_df = df.groupBy("user_id").agg(count("*").alias("row_count"))

# Check if the maximum row count is greater than 1
result_df = grouped_df.agg((max_("row_count") > 1).alias("duplicates"))
```

---

### Date Formatting

SQL:
```sql
SELECT 
	DATE_FORMAT(column, 'mmDDyy')
FROM
	TABLE_1
```

PySpark:
```python
df = spark.read.table("TABLE_1")

df = (
	  df.withColumn("new_column", date_format("column",'mmDDyy').cast("timestamp"))
)
```

---

### JSON Array Operations


 - Check JSON array size:
  ```sql
  SELECT * FROM table WHERE SIZE(column) > 1
  ```
- `collect_set`: Collects unique values for a field
- `flatten`: Combines arrays into a single array
- `array_distinct`: Removes distinct values

![[Pasted image 20240821170521.png]]

![[Pasted image 20240821170509.png]]

> [!TIP]
> Use `column.whatever` to navigate down the array tree.

---

### SQL UDFs

SQL UDFs allow you to register custom SQL logic as functions in the database, making these methods reusable anywhere SQL can be run on Databricks. They are registered locally and take advantage of Spark optimizations when executed.

SQL:
```sql
CREATE OR REPLACE FUNCTION sales_announcement(item_name, item_price)
RETURNS STRING
RETURN CONCAT('The ', item_name, ' is on sale for ', item_price);

SELECT 
	*, 
	sales_announcement(name, price) AS message 
FROM 
	item_lookup
```

- Use `DESCRIBE FUNCTION` to view the SQL logic in the function body.
- Useful for complex `CASE WHEN` statements.

---

### Python UDFs

Python UDFs are custom column transformation functions with some limitations:
- Cannot be optimized by Spark
- Function is serialized and sent to executors
- Requires serialization and deserialization to use the UDF (performance impact)
- Extra communication between the driver and executors

> [!WARNING]
> Python UDFs can have significant performance overhead due to serialization/deserialization and additional communication.


---

### Generated Columns

Generated columns are a special type of column whose values are automatically generated based on the values of other columns.

SQL:
```sql
CREATE TABLE default.people10m (
  id INT,
  firstName STRING,
  middleName STRING,
  lastName STRING,
  gender STRING,
  birthDate TIMESTAMP,
  dateOfBirth DATE GENERATED ALWAYS AS (CAST(birthDate AS DATE)),
  ssn STRING,
  salary INT
)
```


PySpark:
```python
table.create(spark) \
  .tableName("default.people10m") \
  .addColumn("id", "INT") \
  .addColumn("firstName", "STRING") \
  .addColumn("middleName", "STRING") \
  .addColumn("lastName", "STRING", comment = "surname") \
  .addColumn("gender", "STRING") \
  .addColumn("birthDate", "TIMESTAMP") \
  .addColumn("dateOfBirth", DateType(), generatedAlwaysAs="CAST(birthDate AS DATE)") \
  .addColumn("ssn", "STRING") \
  .addColumn("salary", "INT") \
  .execute()

```

---

### Merge

MERGE can combine two tables with configurations for update, insert, or delete operations.

![[Pasted image 20240828113847.png]]
![[Pasted image 20240828113855.png]]

> [!WARNING]
>  Can have problems if a column is generated and the values do not match.
